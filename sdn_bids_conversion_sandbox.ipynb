{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import re\n",
    "from subprocess import call\n",
    "import json\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCAN_EXPR = \"\"\"\\\n",
    "^(?P<rec_ex>PU:)?\\\n",
    "(?P<modality>[a-z]+)?\\\n",
    "(-(?P<label>[a-zA-Z0-9]+))?\\\n",
    "(_task-(?P<task>[a-zA-Z0-9]+))?\\\n",
    "(_acq-(?P<acq>[a-zA-Z0-9]+))?\\\n",
    "(_ce-(?P<ce>[a-zA-Z0-9]+))?\\\n",
    "(_rec-(?P<rec>[a-zA-Z0-9]+))?\\\n",
    "(_dir-(?P<dir>[a-zA-Z0-9]+))?\\\n",
    "(_run-(?P<run>[a-zA-Z0-9]+))?\\\n",
    "(_echo-(?P<echo>[0-9]+))?\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(json_file):\n",
    "    \"\"\"\n",
    "    Parse json file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_file: json\n",
    "        JSON file containing information about which subjects/sessions/scans to\n",
    "        download from which project and where to store the files.\n",
    "    JSON Keys\n",
    "    ---------\n",
    "    destination: string\n",
    "        Directory to construct the BIDS structure\n",
    "    scan_dict: dictionary\n",
    "        a dictionary/hash table where the keys are the scan names on xnat\n",
    "        and the values are the reproin style scan names\n",
    "    session_labels: list\n",
    "        (optional) (non-BIDS) If you want to replace the names of the sessions\n",
    "        on xnat with your own list of scans.\n",
    "    scan_labels: list\n",
    "        (optional) a list of the scans you want to download (if you don't want to\n",
    "        download all the scans).\n",
    "    Returns\n",
    "    -------\n",
    "    input_dict:\n",
    "        A dictionary containing the parameters specified in the JSON file\n",
    "    \"\"\"\n",
    "    import json\n",
    "    with open(json_file) as json_input:\n",
    "        input_dict = json.load(json_input)\n",
    "        # print(str(input_dict))\n",
    "    mandatory_keys = ['destination']\n",
    "    optional_keys = ['session_labels', 'subjects', 'scan_labels',\n",
    "                     'scan_dict', 'num_digits', 'sub_dict', 'sub_label_prefix']\n",
    "    total_keys = mandatory_keys+optional_keys\n",
    "    # print(\"total_keys: \"+str(total_keys))\n",
    "    # are there any inputs in the json_file that are not supported?\n",
    "    extra_inputs = list(set(input_dict.keys()) - set(total_keys))\n",
    "    if extra_inputs:\n",
    "        logging.warning('JSON spec key(s) not supported: %s' % str(extra_inputs))\n",
    "\n",
    "    # are there missing mandatory inputs?\n",
    "    missing_inputs = list(set(mandatory_keys) - set(input_dict.keys()))\n",
    "    if missing_inputs:\n",
    "        raise KeyError('option(s) need to be specified in input file: '\n",
    "                       '%s' % str(missing_inputs))\n",
    "\n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = parse_json(\"bids_conversion_info.json\")\n",
    "scan_repl_dict = input_dict.get('scan_dict', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'destination': '/Users/liza/data/NIH_SDN_BIDS',\n",
       " 'scan_dict': {'anat_t1w_sag_mp_rage_1mm': 'anat-T1w',\n",
       "  'sag_cube_t2': 'anat-T2w',\n",
       "  'resting_epi_3mm_iso_rs': 'func-bold_task-rest',\n",
       "  'edti_2mm_cdif45_ap': 'dwi_acq-AP',\n",
       "  'edti_2mm_cdif45_pa': 'dwi_acq-PA',\n",
       "  'me_mp_rage_1mm_promo_echo-1': 'anat-T1w_acq-multiecho_echo-1',\n",
       "  'me_mp_rage_1mm_promo_echo-2': 'anat-T1w_acq-multiecho_echo-2',\n",
       "  'me_mp_rage_1mm_promo_echo-3': 'anat-T1w_acq-multiecho_echo-3',\n",
       "  'me_mp_rage_1mm_promo_echo-4': 'anat-T1w_acq-multiecho_echo-4',\n",
       "  'reverse_blip_resting_epi_3mm_iso': 'anat-T2star',\n",
       "  't2_1.7mm_fat_sat': 'anat-T2w_acq-fatsat',\n",
       "  'orig_anat_t1w_sag_mp_rage_1mm': 'anat-T1w_rec-orig',\n",
       "  'orig_sag_cube_t2': 'anat-T2w_rec-orig',\n",
       "  'orig_me_mp_rage_1mm_promo_echo-1': 'anat-T1w_acq-multiecho_rec-orig_echo-1',\n",
       "  'orig_me_mp_rage_1mm_promo_echo-2': 'anat-T1w_acq-multiecho_rec-orig_echo-2',\n",
       "  'orig_me_mp_rage_1mm_promo_echo-3': 'anat-T1w_acq-multiecho_rec-orig_echo-3',\n",
       "  'orig_me_mp_rage_1mm_promo_echo-4': 'anat-T1w_acq-multiecho_rec-orig_echo-4'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anat_t1w_sag_mp_rage_1mm': 'anat-T1w',\n",
       " 'sag_cube_t2': 'anat-T2w',\n",
       " 'resting_epi_3mm_iso_rs': 'func-bold_task-rest',\n",
       " 'edti_2mm_cdif45_ap': 'dwi_acq-AP',\n",
       " 'edti_2mm_cdif45_pa': 'dwi_acq-PA',\n",
       " 'me_mp_rage_1mm_promo_echo-1': 'anat-T1w_acq-multiecho_echo-1',\n",
       " 'me_mp_rage_1mm_promo_echo-2': 'anat-T1w_acq-multiecho_echo-2',\n",
       " 'me_mp_rage_1mm_promo_echo-3': 'anat-T1w_acq-multiecho_echo-3',\n",
       " 'me_mp_rage_1mm_promo_echo-4': 'anat-T1w_acq-multiecho_echo-4',\n",
       " 'reverse_blip_resting_epi_3mm_iso': 'anat-T2star',\n",
       " 't2_1.7mm_fat_sat': 'anat-T2w_acq-fatsat',\n",
       " 'orig_anat_t1w_sag_mp_rage_1mm': 'anat-T1w_rec-orig',\n",
       " 'orig_sag_cube_t2': 'anat-T2w_rec-orig',\n",
       " 'orig_me_mp_rage_1mm_promo_echo-1': 'anat-T1w_acq-multiecho_rec-orig_echo-1',\n",
       " 'orig_me_mp_rage_1mm_promo_echo-2': 'anat-T1w_acq-multiecho_rec-orig_echo-2',\n",
       " 'orig_me_mp_rage_1mm_promo_echo-3': 'anat-T1w_acq-multiecho_rec-orig_echo-3',\n",
       " 'orig_me_mp_rage_1mm_promo_echo-4': 'anat-T1w_acq-multiecho_rec-orig_echo-4'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_repl_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_scan_unformatted(self, scan, dest, scan_repl_dict, bids_num_len,\n",
    "                             sub_repl_dict=None, sub_label_prefix=None,\n",
    "                             overwrite_nii=False):\n",
    "        \"\"\"\n",
    "        Downloads a particular scan session\n",
    "        Parameters\n",
    "        ----------\n",
    "        scan: string\n",
    "            Scan object returned from pyxnat.\n",
    "        dest: string\n",
    "            Directory where the zip file will be saved.\n",
    "            The actual dicoms will be saved under the general scheme\n",
    "            <session_label>/scans/<scan_label>/resources/DICOM/files\n",
    "        bids_num_len: int\n",
    "            the number of integers to use to represent the subject label\n",
    "        scan_repl_dict: dict\n",
    "            Dictionary containing terms to match the scan name on xnat with\n",
    "            the reproin name of the scan\n",
    "        sub_label_prefix: string\n",
    "            prefix to add to the subject label (e.g. \"AMBI\")\n",
    "        sub_repl_dict: dict\n",
    "            dictionary to change the subject label based on its representation on xnat\n",
    "        overwrite_nii: bool\n",
    "            overwrite the output nifti file if it already exists\n",
    "        \"\"\"\n",
    "        from glob import glob\n",
    "        if scan not in self.scan_dict.keys():\n",
    "            print('{scan} is not available for download'.format(scan=scan))\n",
    "            return 0\n",
    "\n",
    "        # No easy way to check for complete download\n",
    "        # the session label (e.g. 20180613)\n",
    "        # ^soon to be sub-01_ses-01\n",
    "        ses_dir = self.scan_dict[scan].parent().label()\n",
    "        scan_par = self.scan_dict[scan].parent()\n",
    "        # the number id given to a scan (1, 2, 3, 400, 500)\n",
    "        scan_id = self.scan_dict[scan].id()\n",
    "        if scan not in scan_repl_dict.keys():\n",
    "            print('{scan} not a part of dictionary, skipping'.format(scan=scan))\n",
    "            return 0\n",
    "\n",
    "        bids_scan = scan_repl_dict[scan]\n",
    "        # PU:task-rest_bold -> PU_task_rest_bold\n",
    "        scan_fmt = re.sub(r'[^\\w]', '_', scan)\n",
    "        scan_dir = scan_id + '-' + scan_fmt\n",
    "\n",
    "        dcm_outdir = os.path.join(dest, 'sourcedata')\n",
    "        if not os.path.isdir(dcm_outdir):\n",
    "            os.makedirs(dcm_outdir)\n",
    "\n",
    "        potential_files = glob(os.path.join(dcm_outdir,\n",
    "                                            ses_dir,\n",
    "                                            'scans',\n",
    "                                            scan_dir,\n",
    "                                            'resources/DICOM/files/*.dcm'))\n",
    "        if potential_files:\n",
    "            msg = \"\"\"\n",
    "                  dicoms were already found in the output directory: {}\n",
    "                  \"\"\".format(potential_files[0])\n",
    "            print(msg)\n",
    "        else:\n",
    "            # attempt to download dicoms (with a max of 5 tries)\n",
    "            max_retries = 5\n",
    "            for rtry in range(max_retries):\n",
    "                # track whether download succeeded\n",
    "                err = False\n",
    "                try:\n",
    "                    scan_par.scans().download(dest_dir=dcm_outdir,\n",
    "                                              type=scan_id,\n",
    "                                              name=scan_fmt,\n",
    "                                              extract=True,\n",
    "                                              removeZip=True)\n",
    "                except TypeError:\n",
    "                    print('download attempt {n} failed'.format(n=rtry + 1))\n",
    "                    err = True\n",
    "                    sleep(5)\n",
    "                finally:\n",
    "                    # break out of for loop if download succeeded\n",
    "                    if not err:\n",
    "                        break\n",
    "                    elif rtry == (max_retries - 1):\n",
    "                        raise TypeError(\"Could not download dicom\")\n",
    "\n",
    "        # getting information about the directories\n",
    "        dcm_dir = os.path.join(dcm_outdir,\n",
    "                               ses_dir,\n",
    "                               'scans',\n",
    "                               scan_dir)\n",
    "        if sub_repl_dict:\n",
    "            sub_name = 'sub-' + sub_repl_dict[self.sub_obj.attrs.get('label')]\n",
    "        else:\n",
    "            sub_name = 'sub-' + self.sub_obj.attrs.get('label').zfill(bids_num_len)\n",
    "\n",
    "        if self.ses_name_dict:\n",
    "            ses_name = 'ses-' + self.ses_name_dict[ses_dir]\n",
    "        else:\n",
    "            # To capture cases where the session is named 20180508_2\n",
    "            ses_name = 'ses-' + ses_dir.replace('_', 's')\n",
    "\n",
    "        scan_pattern = re.compile(SCAN_EXPR)\n",
    "\n",
    "        scan_pattern_dict = re.search(scan_pattern, bids_scan).groupdict()\n",
    "        # check if the modality is empty\n",
    "        if scan_pattern_dict['modality'] is None:\n",
    "            print('{scan} is not in BIDS, not converting'.format(scan=scan))\n",
    "            return 0\n",
    "\n",
    "        # adding additional information to scan label (such as GE120)\n",
    "        if sub_label_prefix is not None:\n",
    "            sub_label = sub_name.split('-')[1]\n",
    "            sub_name = 'sub-' + sub_label_prefix + sub_label\n",
    "\n",
    "        # build up the bids directory\n",
    "        bids_dir = os.path.join(dest, sub_name, ses_name, scan_pattern_dict['modality'])\n",
    "\n",
    "        if not os.path.isdir(bids_dir):\n",
    "            os.makedirs(bids_dir)\n",
    "\n",
    "        # name the bids file\n",
    "        fname = '_'.join([sub_name, ses_name])\n",
    "\n",
    "        bids_keys_order = ['task', 'acq', 'ce', 'rec', 'rec_ex', 'dir', 'run', 'echo']\n",
    "\n",
    "        for key in bids_keys_order:\n",
    "            label = scan_pattern_dict[key]\n",
    "            if label is not None:\n",
    "                if key == 'rec_ex':\n",
    "                    key = 'rec'\n",
    "                    label = 'pu'\n",
    "                fname = '_'.join([fname, key + '-' + label])\n",
    "\n",
    "        # add the label (e.g. _bold)\n",
    "        if scan_pattern_dict['label'] is None:\n",
    "            label = scan_pattern_dict['modality']\n",
    "        else:\n",
    "            label = scan_pattern_dict['label']\n",
    "\n",
    "        fname = '_'.join([fname, label])\n",
    "\n",
    "        print('the dcm dir is {dcm_dir}'.format(dcm_dir=dcm_dir))\n",
    "        dcm2niix = 'dcm2niix -o {bids_dir} -f {fname} -z y -b y {dcm_dir}'.format(\n",
    "            bids_dir=bids_dir,\n",
    "            fname=fname,\n",
    "            dcm_dir=dcm_dir)\n",
    "        bids_outfile = os.path.join(bids_dir, fname + '.nii.gz')\n",
    "        if not os.path.exists(bids_outfile) or overwrite_nii:\n",
    "            call(dcm2niix, shell=True)\n",
    "        else:\n",
    "            print('It appears the nifti file already exists for {scan}'.format(scan=scan))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_scan = 'anat-T1rho_acq-SL50'\n",
    "scan_pattern = re.compile(SCAN_EXPR)\n",
    "scan_pattern_dict = re.search(scan_pattern, bids_scan).groupdict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rec_ex': None,\n",
       " 'modality': 'anat',\n",
       " 'label': 'T1rho',\n",
       " 'task': None,\n",
       " 'acq': 'SL50',\n",
       " 'ce': None,\n",
       " 'rec': None,\n",
       " 'dir': None,\n",
       " 'run': None,\n",
       " 'echo': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_pattern_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = \"/Users/liza/data/LASTNAME_FIRSTNAME_MIDDLENAME_MR-0XXXXXXX/YYYYMMDD_XXXXXX/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the text in the README-Study.txt file into a dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mr_dir_description(readme_path): \n",
    "    readme_dict_orig = {} \n",
    "    # creating dictionary \n",
    "    with open(os.path.join(curr_dir, \"README-Study.txt\")) as fh: \n",
    "        for line in fh: \n",
    "            # reads each line and trims of extra the spaces  \n",
    "            # and gives only the valid words \n",
    "            command, description = line.strip().split(None, 1) \n",
    "            readme_dict_orig[command] = description.strip() \n",
    "    mr_dir_dict = {}\n",
    "    for key in readme_dict_orig.keys(): \n",
    "        if \"Series\" in key: \n",
    "            mr_dir = key.split(\":\")[1].split(\",\")[0]\n",
    "            metadata = [x.lstrip() for x in readme_dict_orig[key].split(\",\")]\n",
    "            description = metadata[2].split(\")\")[-1]\n",
    "            mr_dir_dict[mr_dir] = description\n",
    "    return mr_dir_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_dir_dict = extract_mr_dir_description(os.path.join(curr_dir, \"README-Study.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_dir_dict['subject'] = '09XRZ'\n",
    "mr_dir_dict['session'] = '01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "j=1\n",
    "for key in mr_dir_dict.keys(): \n",
    "    if mr_dir_dict[key] == \"me_mp_rage_1mm_promo\": \n",
    "        mr_dir_dict[key] = \"me_mp_rage_1mm_promo_echo-{0}\".format(i) \n",
    "        i += 1\n",
    "    elif mr_dir_dict[key] == \"orig_me_mp_rage_1mm_promo\": \n",
    "        mr_dir_dict[key] = \"orig_me_mp_rage_1mm_promo_echo-{0}\".format(j) \n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mr_0001': '3_plane_localizer',\n",
       " 'mr_0002': 'sag_t1_spin_echo',\n",
       " 'mr_0003': 'ax_t2_frfse',\n",
       " 'mr_0004': 'ax_t2_flair',\n",
       " 'mr_0005': 'asset_pure_calibration',\n",
       " 'mr_0006': 'anat_t1w_sag_mp_rage_1mm',\n",
       " 'mr_0007': 'sag_cube_t2',\n",
       " 'mr_0008': 'me_mp_rage_1mm_promo_echo-1',\n",
       " 'mr_0008-e02': 'me_mp_rage_1mm_promo_echo-2',\n",
       " 'mr_0008-e03': 'me_mp_rage_1mm_promo_echo-3',\n",
       " 'mr_0008-e04': 'me_mp_rage_1mm_promo_echo-4',\n",
       " 'mr_0009': 'sagittal_ref_pa_fr8',\n",
       " 'mr_0010': 'sagittal_ref_body_fr8',\n",
       " 'mr_0012': 'resting_epi_3mm_iso_rs',\n",
       " 'mr_0013': 'reverse_blip_resting_epi_3mm_iso',\n",
       " 'mr_0015': 'edti_2mm_cdif45_ap',\n",
       " 'mr_0016': 'edti_2mm_cdif45_pa',\n",
       " 'mr_0017': 't2_1.7mm_fat_sat',\n",
       " 'mr_40006': 'orig_anat_t1w_sag_mp_rage_1mm',\n",
       " 'mr_40007': 'orig_sag_cube_t2',\n",
       " 'mr_40008': 'orig_me_mp_rage_1mm_promo_echo-1',\n",
       " 'mr_40008-e02': 'orig_me_mp_rage_1mm_promo_echo-2',\n",
       " 'mr_40008-e03': 'orig_me_mp_rage_1mm_promo_echo-3',\n",
       " 'mr_40008-e04': 'orig_me_mp_rage_1mm_promo_echo-4',\n",
       " 'sc_0000': 'requisition',\n",
       " 'sc_20005': 'screen_save',\n",
       " 'sc_20015': 'screen_save',\n",
       " 'sc_20016': 'screen_save',\n",
       " 'sc_20017': 'screen_save',\n",
       " 'subject': '09XRZ',\n",
       " 'session': '01'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_dir_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anat_t1w_sag_mp_rage_1mm': 'anat-T1w',\n",
       " 'sag_cube_t2': 'anat-T2w',\n",
       " 'resting_epi_3mm_iso_rs': 'func-bold_task-rest',\n",
       " 'edti_2mm_cdif45_ap': 'dwi_rec-PA',\n",
       " 'me_mp_rage_1mm_promo_echo-1': 'anat-T1w_acq-multiecho_echo-1',\n",
       " 'me_mp_rage_1mm_promo_echo-2': 'anat-T1w_acq-multiecho_echo-2',\n",
       " 'me_mp_rage_1mm_promo_echo-3': 'anat-T1w_acq-multiecho_echo-3',\n",
       " 'me_mp_rage_1mm_promo_echo-4': 'anat-T1w_acq-multiecho_echo-4',\n",
       " 'reverse_blip_resting_epi_3mm_iso': 'anat-T2star',\n",
       " 't2_1.7mm_fat_sat': 'anat-T2w_acq-fatsat',\n",
       " 'orig_anat_t1w_sag_mp_rage_1mm': 'anat-T1w_rec-orig',\n",
       " 'orig_sag_cube_t2': 'anat-T2w_rec-orig',\n",
       " 'orig_me_mp_rage_1mm_promo_echo-1': 'anat-T1w_acq-multiecho_rec-orig_echo-1',\n",
       " 'orig_me_mp_rage_1mm_promo_echo-2': 'anat-T1w_acq-multiecho_rec-orig_echo-2',\n",
       " 'orig_me_mp_rage_1mm_promo_echo-3': 'anat-T1w_acq-multiecho_rec-orig_echo-3',\n",
       " 'orig_me_mp_rage_1mm_promo_echo-4': 'anat-T1w_acq-multiecho_rec-orig_echo-4'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_repl_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_T2w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-multiecho_echo-1_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-multiecho_echo-2_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-multiecho_echo-3_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-multiecho_echo-4_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/func/sub-09XRZ_ses-01_task-rest_bold.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_T2star.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/dwi/sub-09XRZ_ses-01_acq-AP_dwi.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/dwi/sub-09XRZ_ses-01_acq-PA_dwi.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-fatsat_T2w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_rec-orig_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_rec-orig_T2w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-multiecho_rec-orig_echo-1_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-multiecho_rec-orig_echo-2_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-multiecho_rec-orig_echo-3_T1w.nii.gz\n",
      "/Users/liza/data/NIH_SDN_BIDS/sub-09XRZ/ses-01/anat/sub-09XRZ_ses-01_acq-multiecho_rec-orig_echo-4_T1w.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for mr_key in mr_dir_dict.keys():\n",
    "    sub_name = 'sub-' + mr_dir_dict['subject'] \n",
    "    ses_name = 'ses-' + mr_dir_dict['session']\n",
    "    scan = mr_dir_dict[mr_key]\n",
    "    dest = input_dict['destination']\n",
    "    if scan in scan_repl_dict.keys():\n",
    "#         print('{scan} is a part of dictionary'.format(scan=scan))\n",
    "        dcm_dir = os.path.join(curr_dir, mr_key)\n",
    "        bids_scan = scan_repl_dict[scan]\n",
    "        # PU:task-rest_bold -> PU_task_rest_bold\n",
    "        scan_fmt = re.sub(r'[^\\w]', '_', scan)        \n",
    "        scan_pattern = re.compile(SCAN_EXPR)\n",
    "\n",
    "        scan_pattern_dict = re.search(scan_pattern, bids_scan).groupdict()\n",
    "\n",
    "        # build up the bids directory\n",
    "        bids_dir = os.path.join(dest, sub_name, ses_name, scan_pattern_dict['modality'])\n",
    "#         print(bids_dir)\n",
    "        if not os.path.isdir(bids_dir):\n",
    "            os.makedirs(bids_dir)\n",
    "        \n",
    "        # name the bids file\n",
    "        fname = '_'.join([sub_name, ses_name])\n",
    "\n",
    "        bids_keys_order = ['task', 'acq', 'ce', 'rec', 'rec_ex', 'dir', 'run', 'echo']\n",
    "\n",
    "        for key in bids_keys_order:\n",
    "            label = scan_pattern_dict[key]\n",
    "            if label is not None:\n",
    "                if key == 'rec_ex':\n",
    "                    key = 'rec'\n",
    "                    label = 'pu'\n",
    "                fname = '_'.join([fname, key + '-' + label])\n",
    "\n",
    "        # add the label (e.g. _bold)\n",
    "        if scan_pattern_dict['label'] is None:\n",
    "            label = scan_pattern_dict['modality']\n",
    "        else:\n",
    "            label = scan_pattern_dict['label']\n",
    "\n",
    "        fname = '_'.join([fname, label])\n",
    "\n",
    "#         print('the dcm dir is {dcm_dir}'.format(dcm_dir=dcm_dir))\n",
    "        dcm2niix = 'dcm2niix -o {bids_dir} -f {fname} -z y -b y {dcm_dir}'.format(\n",
    "            bids_dir=bids_dir,\n",
    "            fname=fname,\n",
    "            dcm_dir=dcm_dir)\n",
    "        bids_outfile = os.path.join(bids_dir, fname + '.nii.gz')\n",
    "        print(bids_outfile)\n",
    "        if not os.path.exists(bids_outfile) or overwrite_nii:\n",
    "            call(dcm2niix, shell=True)\n",
    "        else:\n",
    "            print('It appears the nifti file already exists for {scan}'.format(scan=scan))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
